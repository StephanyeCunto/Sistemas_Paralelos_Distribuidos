# AnÃ¡lise de Desempenho: Contagem de Palavras em Java com Abordagens Sequencial e Paralela

## ğŸ“š Contexto da Atividade

Este projeto foi desenvolvido como parte da disciplina "Sistemas Paralelos e DistribuÃ­dos" do Instituto Federal de EducaÃ§Ã£o, CiÃªncia e Tecnologia do Sudeste de Minas Gerais, Campus Rio Pomba. A atividade propÃµe a implementaÃ§Ã£o e anÃ¡lise comparativa entre algoritmos sequenciais e paralelos para contagem de palavras em um texto literÃ¡rio.

### O Projeto Gutenberg

O texto utilizado para anÃ¡lise provÃ©m do Projeto Gutenberg, que disponibiliza mais de 60.000 e-books gratuitos de domÃ­nio pÃºblico. A obra escolhida foi "Clarissa Harlowe; or the history of a young lady" de Samuel Richardson, considerada um dos livros mais longos jÃ¡ escritos em lÃ­ngua inglesa.

## ğŸ¯ Objetivos do Projeto

- Comparar desempenho entre duas abordagens de contagem de palavras:
  - ImplementaÃ§Ã£o **sequencial**
  - ImplementaÃ§Ã£o **paralela com mÃºltiplas threads**

- Desenvolver um benchmark que:
  - Execute ambas as abordagens repetidamente
  - MeÃ§a e registre os tempos de execuÃ§Ã£o
  - Produza dados confiÃ¡veis para anÃ¡lise estatÃ­stica e comparaÃ§Ã£o

- Analisar os **ganhos de desempenho (speedup)** e a **eficiÃªncia** do paralelismo

## ğŸ—ï¸ Arquitetura do Sistema

O sistema estÃ¡ estruturado em trÃªs mÃ³dulos principais:

### 1. MÃ³dulo Initialize
ResponsÃ¡vel pela coordenaÃ§Ã£o geral do benchmark, incluindo:
- Leitura do arquivo PDF
- ExtraÃ§Ã£o das palavras
- ExecuÃ§Ã£o das estratÃ©gias sequencial e paralela
- Coleta dos tempos de execuÃ§Ã£o
- Processamento estatÃ­stico dos dados

### 2. MÃ³dulo Sequencial
Implementa a estratÃ©gia de contagem sequencial:
- Recebe as palavras a serem contadas como argumentos
- Processa o texto palavra por palavra em tempo real, sem armazenamento em memÃ³ria
- Contabiliza as ocorrÃªncias de cada palavra alvo

### 3. MÃ³dulo Paralelo
Implementa a estratÃ©gia de contagem com paralelismo:
- Carrega todas as palavras em um array em memÃ³ria antes do processamento
- Divide o processamento entre mÃºltiplas threads
- Utiliza estruturas thread-safe para contabilizaÃ§Ã£o concorrente
- Permite parametrizaÃ§Ã£o do nÃºmero de threads

## ğŸ“Š Diagrama de Classes

```mermaid
classDiagram
    class Main {
        -String[][] SEARCH_WORDS
        -int[] THREAD
        -int INTERATIONS
        -String[] words
        -int[][] timeSequencial
        -int[][][] timeParalelo
        +main(String[] args) void
        -run() void
    }
    
    class OpenPDF {
        -String[] words
        +OpenPDF(String filePath)
        -openPDF(File file) void
        -extractWords(String text) void
        +getWords() String[]
    }
    
    class Programas {
        #String[][] SEARCH_WORDS
        #int INTERATIONS
        #String[] WORDS
        #abstract initialize() void
        #initializeProcess(List~String~ command) Process
        #getResultSearch(Process process) String[]
        #getErro(Process process) String[]
        #closeProcess(Process process) void
        #createCommand(int i, String process) List~String~
        #writeWordsToProcess(OutputStream os) void
        #getTime(String resultSearch) int
        +getSEARCH_WORDS() String[][]
        +getINTERATIONS() int
        +getWORDS() String[]
    }
    
    class Sequencial {
        -int[][] timeSequencial
        +Sequencial(String[][] SEARCH_WORDS, int INTERATIONS, String[] WORDS)
        #initialize() void
        +getTimeSequencial() int[][]
    }
    
    class Paralelo {
        -int[] THREAD
        -int[][][] timeParalelo
        +Paralelo(String[][] SEARCH_WORDS, int[] THREAD, int INTERATIONS, String[] WORDS)
        #initialize() void
        +getTHREAD() int[]
        +getTimeParalelo() int[][][]
    }
    
    class ProcessData {
        -int[][] timeSequencial
        -int[][][] timeParalelo
        -int iterations
        -int[] threads
        -double[] timeSequencialAverage
        -double[][] timeParaleloAverage
        -double[] timeSequencialStdDev
        -double[][] timeParaleloStdDev
        -double[][] speedup
        -double[][] efficiency
        -final static int WARMUP
        +ProcessData(int[][] timeSequencial, int[][][] timeParalelo, int iterations, int[] threads)
        -processData() void
        -removeWarmUp() void
        -removeOutliers() void
        -removeOutliersFromArray(int[] times) int[]
        -calculateStatistics() void
        -calculateSpeedupEfficiency() void
        +print() void
    }
    
    class CountWordsSequencial {
        ~String[] words
        ~int[] searchWordsCount
        ~Map~String, Integer~ wordMap
        +main(String[] args) void
        -run(String[] args) void
        -initialize(String[] args) void
        -loadWords() void
        -searchWord(String word) void
        -loadResults() void
    }
    
    class CountWordsParalelo {
        ~String[] words
        ~AtomicInteger[] searchWordsCount
        ~int threads
        ~BufferedReader reader
        ~Map~String, Integer~ wordMap
        +main(String[] args) void
        -run(String[] args) void
        -initialize(String[] args) void
        -loadWords() void
        -initializeThread() void
        -initializeSearch(int indice, int wordsPerThread) void
        -searchWord(String word) void
        -loadResults() void
    }
    
    Main --> OpenPDF : usa
    Main --> Sequencial : usa
    Main --> Paralelo : usa
    Main --> ProcessData : usa
    Sequencial --|> Programas : extends
    Paralelo --|> Programas : extends
```

## ğŸ’» Metodologia de Benchmark

O sistema realiza os seguintes experimentos:

1. **Programa A (Sequencial)**:
   - 30 execuÃ§Ãµes

2. **Programa B (Paralelo)** com trÃªs configuraÃ§Ãµes:
   - 30 execuÃ§Ãµes com 2 threads
   - 30 execuÃ§Ãµes com 4 threads
   - 30 execuÃ§Ãµes com 8 threads

Para garantir mediÃ§Ãµes estatisticamente relevantes, o sistema:
- Remove as primeiras execuÃ§Ãµes (warm-up)
- Elimina outliers usando o mÃ©todo de intervalo interquartil (IQR)
- Calcula mÃ©dia, desvio padrÃ£o, speedup e eficiÃªncia

Dois conjuntos de palavras foram testados:
1. Palavras frequentes: "clarissa", "letter", "lovelace", "virtue", "dear", "miss"
2. Palavras raras: "eita", "bacana", "vixe", "forbidden", "indignation", "oppression"

## ğŸ“ˆ Resultados de Performance

### Conjunto de Palavras Frequentes

```
============================================== RESULTADOS DE PERFORMANCE ===============================================
ğŸ” CONJUNTO DE PALAVRAS 1
â”‚ SEQUENCIAL    â”‚ Tempo mÃ©dio:    64,37 ms â”‚ Desvio padrÃ£o:     0,69 ms â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   PARALELO    â”‚       TEMPO MÃ‰DIO       â”‚      DESVIO PADRÃƒO       â”‚      SPEEDUP      â”‚          EFICIÃŠNCIA          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  2 Threads    â”‚    99,25 ms             â”‚     0,97 ms              â”‚   0,65x           â”‚   32,43%                     â”‚
â”‚  4 Threads    â”‚   103,93 ms             â”‚     1,80 ms              â”‚   0,62x           â”‚   15,48%                     â”‚
â”‚  8 Threads    â”‚   111,81 ms             â”‚     2,88 ms              â”‚   0,58x           â”‚    7,20%                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Conjunto de Palavras Raras

```
ğŸ” CONJUNTO DE PALAVRAS 2
â”‚ SEQUENCIAL    â”‚ Tempo mÃ©dio:    64,00 ms â”‚ Desvio padrÃ£o:     0,00 ms â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   PARALELO    â”‚       TEMPO MÃ‰DIO       â”‚      DESVIO PADRÃƒO       â”‚      SPEEDUP      â”‚          EFICIÃŠNCIA          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  2 Threads    â”‚    98,64 ms             â”‚     1,13 ms              â”‚   0,65x           â”‚   32,44%                     â”‚
â”‚  4 Threads    â”‚   103,25 ms             â”‚     1,46 ms              â”‚   0,62x           â”‚   15,50%                     â”‚
â”‚  8 Threads    â”‚   116,68 ms             â”‚     6,66 ms              â”‚   0,55x           â”‚    6,86%                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
=======================================================================================================================
```

## ğŸ” AnÃ¡lise e DiscussÃ£o dos Resultados

### Por que a versÃ£o sequencial foi mais rÃ¡pida?

Contrariamente ao esperado, nossa implementaÃ§Ã£o sequencial superou significativamente a versÃ£o paralela em todos os casos. O speedup foi consistentemente menor que 1 (0,55x a 0,65x), indicando uma degradaÃ§Ã£o de desempenho na versÃ£o paralela. Este resultado surpreendente pode ser explicado por vÃ¡rios fatores:

1. **DiferenÃ§a fundamental na manipulaÃ§Ã£o de dados**: 
   - A versÃ£o sequencial processa cada palavra em streaming (uma por vez), sem armazenar o texto completo em memÃ³ria
   - A versÃ£o paralela carrega todo o array de palavras antes de iniciar o processamento
   
2. **Sobrecarga de gerenciamento de threads**: 
   - Criar, inicializar e sincronizar threads tem um custo computacional significativo
   - A comunicaÃ§Ã£o entre threads e o gerenciamento de memÃ³ria compartilhada introduz latÃªncia

3. **ContenÃ§Ã£o de recursos**: 
   - As estruturas thread-safe (`AtomicInteger`) usadas para contagem concorrente introduzem overhead
   - A sincronizaÃ§Ã£o necessÃ¡ria para garantir a integridade dos dados cria gargalos

4. **Uso de memÃ³ria e localidade de cache**:
   - A versÃ£o sequencial tem melhor localidade de cache por processar dados sequencialmente
   - A versÃ£o paralela pode sofrer com invalidaÃ§Ãµes de cache e aumentar a taxa de cache miss

5. **Complexidade do problema**:
   - A contagem de palavras Ã© uma operaÃ§Ã£o relativamente simples e rÃ¡pida
   - O overhead do paralelismo supera os ganhos para operaÃ§Ãµes computacionalmente leves

### Impacto do hardware utilizado

#### Hardware utilizado
- **Processador**: Apple Silicon M2 (8 nÃºcleos - 4 de performance e 4 de eficiÃªncia)
- **MemÃ³ria RAM**: 8GB RAM unificada
- **Armazenamento**: SSD interno

**InfluÃªncia do hardware**: A arquitetura do M2 apresenta caracterÃ­sticas particulares que podem amplificar os problemas da implementaÃ§Ã£o paralela:

1. **Heterogeneidade de nÃºcleos**: Os 4 nÃºcleos de eficiÃªncia do M2 tÃªm desempenho significativamente inferior aos nÃºcleos de performance. Quando distribuÃ­mos threads igualmente, algumas podem executar em nÃºcleos mais lentos.

2. **Escalonamento do sistema operacional**: O macOS pode nÃ£o distribuir idealmente as threads entre os nÃºcleos disponÃ­veis.

3. **MemÃ³ria unificada**: O compartilhamento de memÃ³ria entre CPU e GPU pode introduzir custos adicionais de sincronizaÃ§Ã£o quando mÃºltiplas threads acessam dados.

### DegradaÃ§Ã£o de desempenho com mais threads

Ã‰ notÃ¡vel que o desempenho piora progressivamente Ã  medida que aumentamos o nÃºmero de threads:
- 2 threads: ~0,65x speedup (pior que sequencial)
- 4 threads: ~0,62x speedup (ainda pior)
- 8 threads: ~0,55x speedup (o pior caso)

Isso sugere que:

1. **O overhead de comunicaÃ§Ã£o cresce linearmente** com o nÃºmero de threads
2. **A contenÃ§Ã£o de recursos aumenta** com mais threads competindo pelos mesmos dados
3. **LimitaÃ§Ã£o do scheduler**: O sistema operacional pode nÃ£o conseguir escalonar efetivamente tantas threads, especialmente considerando a arquitetura heterogÃªnea do M2

### ComparaÃ§Ã£o entre conjuntos de palavras

Os resultados sÃ£o bastante consistentes entre os dois conjuntos de palavras, com diferenÃ§as mÃ­nimas:

- Para palavras frequentes: Speedup de 0,65x a 0,58x
- Para palavras raras: Speedup de 0,65x a 0,55x

Isso indica que a frequÃªncia das palavras tem pouco impacto no desempenho relativo, sugerindo que o gargalo estÃ¡ mais relacionado Ã  arquitetura da soluÃ§Ã£o do que aos padrÃµes especÃ­ficos dos dados.

## ğŸ§  LiÃ§Ãµes Aprendidas e RecomendaÃ§Ãµes

### 1. Nem sempre mais Ã© melhor

O paralelismo nÃ£o Ã© uma soluÃ§Ã£o universal para melhorar o desempenho. Este projeto demonstra claramente que paralelizar tarefas simples pode piorar significativamente o desempenho devido ao overhead introduzido.

### 2. A importÃ¢ncia da estratÃ©gia de I/O

A diferenÃ§a fundamental entre as implementaÃ§Ãµes nÃ£o estÃ¡ apenas no paralelismo, mas na estratÃ©gia de manipulaÃ§Ã£o de dados:
- O processamento de streaming (sequencial) evitou armazenar todo o conjunto de dados na memÃ³ria
- A carga completa do array (paralelo) aumentou o uso de memÃ³ria e possivelmente afetou o desempenho

### 3. Avalie a granularidade da tarefa

Para tarefas de baixa complexidade computacional como contagem de palavras, o overhead do paralelismo pode facilmente superar os ganhos. O paralelismo funciona melhor para:
- OperaÃ§Ãµes computacionalmente intensivas
- Problemas facilmente divisÃ­veis com pouca necessidade de comunicaÃ§Ã£o
- Conjuntos de dados grandes onde o processamento por item Ã© significativo

### 4. RecomendaÃ§Ãµes para melhorar o desempenho paralelo

Se prosseguirmos com a abordagem paralela, poderÃ­amos:

1. **Implementar processamento streaming tambÃ©m na versÃ£o paralela**
2. **Reduzir a granularidade da divisÃ£o** (chunks maiores por thread)
3. **Utilizar estruturas de dados mais eficientes**, como contadores locais por thread com sincronizaÃ§Ã£o apenas no final
4. **Explorar paralelismo em nÃ­vel de tarefa** em vez de paralelismo de dados
5. **Adotar um ThreadPool** em vez de criar threads manualmente

## ğŸ› ï¸ Tecnologias Utilizadas

- **Java**: Linguagem de programaÃ§Ã£o principal
- **Apache PDFBox**: Biblioteca para leitura e extraÃ§Ã£o de texto de arquivos PDF
- **Apache Commons Math**: Biblioteca para cÃ¡lculos estatÃ­sticos (mÃ©dia, desvio padrÃ£o, percentis)
- **Lombok**: Biblioteca para reduÃ§Ã£o de cÃ³digo boilerplate via anotaÃ§Ãµes
- **Maven**: Gerenciamento de dependÃªncias e build

## ğŸš€ Como Executar

### PrÃ©-requisitos
- Java JDK 11 ou superior
- Maven 3.6 ou superior

### Passos para execuÃ§Ã£o

1. Clone o repositÃ³rio:
```bash
git clone https://github.com/StephanyeCunto/Sistemas_Paralelos_Distribuidos.git
cd Atividade_Avaliativa
```

2. Compile os mÃ³dulos:
```bash
# MÃ³dulo Sequencial
cd sequencial
mvn clean package
cd ..

# MÃ³dulo Paralelo
cd paralelo
mvn clean package
cd ..

# MÃ³dulo Initialize (benchmark)
cd initialize
mvn clean package
cd ..
```

3. Execute o benchmark:
```bash
cd initialize
java -jar target/initialize-1.0-SNAPSHOT.jar
```

4. Os resultados serÃ£o exibidos no console ao final da execuÃ§Ã£o.

## ğŸ“ ConclusÃµes

Este projeto forneceu informaÃ§Ãµes valiosas sobre os desafios da programaÃ§Ã£o paralela, demonstrando que nem sempre a paralelizaÃ§Ã£o resulta em ganhos de desempenho. As principais conclusÃµes sÃ£o:

1. **O contexto importa**: Para operaÃ§Ãµes simples como contagem de palavras, o overhead de gerenciamento de threads pode anular quaisquer ganhos de paralelismo.

2. **EstratÃ©gias de processamento de dados**: A diferenÃ§a entre processamento streaming e carregamento completo em memÃ³ria teve impacto significativo no desempenho.

3. **Mais threads nem sempre sÃ£o melhores**: Adicionar mais threads consistentemente piorou o desempenho, evidenciando que o problema nÃ£o foi a falta de paralelismo, mas sim o overhead associado.

4. **Hardware-especÃ­fico**: A arquitetura heterogÃªnea do M2 introduz complexidades adicionais para workloads paralelos que podem nÃ£o estar presentes em CPUs tradicionais.

Este projeto reforÃ§a a importÃ¢ncia de realizar benchmarks empÃ­ricos antes de optar por soluÃ§Ãµes paralelas e destaca que o paralelismo deve ser aplicado criteriosamente, considerando cuidadosamente a natureza do problema, o hardware disponÃ­vel e os overheads associados.

## ğŸ“š ReferÃªncias

1. Herlihy, M., & Shavit, N. (2012). *The Art of Multiprocessor Programming, Revised Reprint*. Morgan Kaufmann.

2. Goetz, B., Peierls, T., Bloch, J., Bowbeer, J., Holmes, D., & Lea, D. (2006). *Java Concurrency in Practice*. Addison-Wesley Professional.

3. Patterson, D. A., & Hennessy, J. L. (2017). *Computer Organization and Design RISC-V Edition: The Hardware Software Interface*. Morgan Kaufmann.

4. Oracle. (2023). [Java Thread Documentation](https://docs.oracle.com/javase/tutorial/essential/concurrency/).

5. Project Gutenberg. (2023). [Clarissa Harlowe; or the history of a young lady](https://www.gutenberg.org/).

6. Amdahl, G. M. (1967). *Validity of the single processor approach to achieving large scale computing capabilities*. Proceedings of the April 18-20, 1967, spring joint computer conference (pp. 483-485).

7. McCool, M. D., Robison, A. D., & Reinders, J. (2012). *Structured Parallel Programming: Patterns for Efficient Computation*. Morgan Kaufmann.

8. Apache PDFBox. (2023). [Reading PDF Documents](https://pdfbox.apache.org/).

9. Apache Commons Math. (2023). [Statistics Documentation](https://commons.apache.org/proper/commons-math/).

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ licenciado sob a [LicenÃ§a MIT](LICENSE) - veja o arquivo LICENSE para detalhes.

---

<div align="center">
  <p>Desenvolvido com â¤ï¸ para a disciplina de Sistemas Paralelos e DistribuÃ­dos</p>
  <p>Instituto Federal de EducaÃ§Ã£o, CiÃªncia e Tecnologia do Sudeste de Minas Gerais, Campus Rio Pomba</p>
</div>
